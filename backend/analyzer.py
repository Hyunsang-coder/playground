import json
import asyncio
from typing import AsyncGenerator
import httpx
import anthropic


class IdeaAnalyzer:
    def __init__(self, anthropic_api_key: str, tavily_api_key: str, github_token: str = ""):
        self.anthropic_client = anthropic.AsyncAnthropic(api_key=anthropic_api_key) if anthropic_api_key else None
        self.tavily_api_key = tavily_api_key
        self.github_token = github_token

    async def analyze(self, idea: str, mode: str) -> AsyncGenerator[dict, None]:
        """Main analysis pipeline â€” streams SSE events step by step."""

        # Pre-step: AI generates optimized search queries + identifies key data sources
        search_queries = await self._generate_search_queries(idea)

        # Step 1 & 2: Run web search and GitHub search in parallel
        web_queries_display = " / ".join(search_queries.get("web_queries", [idea])[:2])
        gh_query_display = search_queries.get("github_query", idea)

        yield {"event": "step_start", "data": {"step": 1, "title": "ê²½ìŸ ì œí’ˆ íƒìƒ‰", "description": f"AI ìµœì í™” í‚¤ì›Œë“œë¡œ ê²€ìƒ‰ ì¤‘: {web_queries_display}"}}
        yield {"event": "step_start", "data": {"step": 2, "title": "GitHub ìœ ì‚¬ í”„ë¡œì íŠ¸ íƒìƒ‰", "description": f"AI ìµœì í™” í‚¤ì›Œë“œë¡œ ê²€ìƒ‰ ì¤‘: {gh_query_display}"}}

        # Parallel execution
        competitors, github_results = await asyncio.gather(
            self._search_web(idea, search_queries.get("web_queries", [])),
            self._search_github(idea, search_queries.get("github_query", "")),
        )

        yield {"event": "step_result", "data": {"step": 1, "result": competitors}}
        yield {"event": "step_result", "data": {"step": 2, "result": github_results}}

        # Between Step 2 and 3: AI filters search results for relevance
        yield {"event": "step_progress", "data": {"step": 3, "text": "ê²€ìƒ‰ ê²°ê³¼ ê´€ë ¨ì„± í•„í„°ë§ ì¤‘..."}}
        filtered = await self._filter_relevance(idea, competitors, github_results)

        # Step 3: Technical feasibility analysis (with real data + API verification)
        yield {"event": "step_start", "data": {"step": 3, "title": "ê¸°ìˆ  ì‹¤í˜„ì„± ë¶„ì„", "description": "ë°ì´í„° ì†ŒìŠ¤ ì ‘ê·¼ì„± ë° ê¸°ìˆ  êµ¬í˜„ ê°€ëŠ¥ì„±ì„ ê²€ì¦í•˜ê³  ìˆìŠµë‹ˆë‹¤..."}}
        await asyncio.sleep(0.3)

        # Run API/data source verification in parallel with AI analysis
        api_check = await self._check_data_sources(idea, search_queries.get("required_apis", []))

        feasibility = None
        async for event in self._stream_feasibility(idea, mode, filtered, api_check):
            if event["type"] == "progress":
                yield {"event": "step_progress", "data": {"step": 3, "text": event["text"]}}
            else:
                feasibility = event["result"]
        yield {"event": "step_result", "data": {"step": 3, "result": feasibility}}

        # Step 4: Differentiation analysis (with full competitor data)
        yield {"event": "step_start", "data": {"step": 4, "title": "ì°¨ë³„í™” ë¶„ì„", "description": "ê¸°ì¡´ ì œí’ˆ ëŒ€ë¹„ ì°¨ë³„ì ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."}}
        await asyncio.sleep(0.3)

        differentiation = None
        async for event in self._stream_differentiation(idea, filtered):
            if event["type"] == "progress":
                yield {"event": "step_progress", "data": {"step": 4, "text": event["text"]}}
            else:
                differentiation = event["result"]
        yield {"event": "step_result", "data": {"step": 4, "result": differentiation}}

        # Step 5: Final verdict (with ALL analysis data)
        yield {"event": "step_start", "data": {"step": 5, "title": "ì¢…í•© íŒì •", "description": "ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ êµì°¨ ê²€ì¦í•˜ê³  ìµœì¢… ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤..."}}
        await asyncio.sleep(0.3)

        verdict = None
        async for event in self._stream_verdict(idea, mode, filtered, feasibility, differentiation, api_check):
            if event["type"] == "progress":
                yield {"event": "step_progress", "data": {"step": 5, "text": event["text"]}}
            else:
                verdict = event["result"]
        yield {"event": "step_result", "data": {"step": 5, "result": verdict}}

        yield {"event": "done", "data": {"message": "ë¶„ì„ ì™„ë£Œ"}}

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Pre-step: AI search query generation + API identification
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def _generate_search_queries(self, idea: str) -> dict:
        """Use Claude to generate optimized search queries AND identify required APIs/data sources."""
        if not self.anthropic_client:
            return {
                "web_queries": [f"{idea} tool service app", f"{idea} alternative competitor"],
                "github_query": idea,
                "required_apis": [],
            }

        prompt = f"""ì‚¬ìš©ìì˜ ì•„ì´ë””ì–´ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒì„ ìƒì„±í•˜ì„¸ìš”:
1. ê²½ìŸ ì œí’ˆì„ ì°¾ê¸° ìœ„í•œ ìµœì  ê²€ìƒ‰ í‚¤ì›Œë“œ
2. ì´ ì•„ì´ë””ì–´ë¥¼ êµ¬í˜„í•˜ëŠ” ë° í•„ìš”í•œ í•µì‹¬ ë°ì´í„° ì†ŒìŠ¤/API ëª©ë¡

ì•„ì´ë””ì–´: {idea}

ë°˜ë“œì‹œ ìˆœìˆ˜ JSONìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:

{{
  "web_queries": ["ì˜ì–´ ì›¹ ê²€ìƒ‰ ì¿¼ë¦¬ 1", "ì˜ì–´ ì›¹ ê²€ìƒ‰ ì¿¼ë¦¬ 2"],
  "github_query": "GitHub ê²€ìƒ‰ì— ìµœì í™”ëœ ì˜ì–´ í‚¤ì›Œë“œ",
  "required_apis": [
    {{
      "name": "ë°ì´í„° ì†ŒìŠ¤/APIëª… (ì˜ˆ: Naver Review API, Twitter API)",
      "purpose": "ì´ APIê°€ í•„ìš”í•œ ì´ìœ ",
      "check_url": "API ì¡´ì¬ ì—¬ë¶€ë¥¼ í™•ì¸í•  ìˆ˜ ìˆëŠ” ê³µì‹ ë¬¸ì„œ URL ë˜ëŠ” ë¹ˆ ë¬¸ìì—´",
      "alternatives": ["ëŒ€ì•ˆ 1", "ëŒ€ì•ˆ 2"],
      "known_blocked": true/false
    }}
  ]
}}

ê·œì¹™:
- web_queries: ì •í™•íˆ 2ê°œì˜ ì˜ì–´ ê²€ìƒ‰ ì¿¼ë¦¬
- github_query: GitHub ì €ì¥ì†Œ ê²€ìƒ‰ì— ì í•©í•œ ì˜ì–´ í‚¤ì›Œë“œ (2~4ë‹¨ì–´)
- required_apis: ì•„ì´ë””ì–´ êµ¬í˜„ì— í•„ìˆ˜ì ì¸ ì™¸ë¶€ ë°ì´í„° ì†ŒìŠ¤ë¥¼ ëª¨ë‘ ë‚˜ì—´
  - í¬ë¡¤ë§ì´ ì°¨ë‹¨ëœ ê²ƒìœ¼ë¡œ ì•Œë ¤ì§„ ì‚¬ì´íŠ¸(ë„¤ì´ë²„, ì¿ íŒ¡, ë°°ë¯¼ ë“±)ëŠ” known_blocked: true
  - ê³µì‹ APIê°€ ì—†ê±°ë‚˜ ì œí•œì ì¸ ê²½ìš°ë„ ëª…ì‹œ
  - ëŒ€ì•ˆì´ ìˆìœ¼ë©´ alternativesì— í¬í•¨"""

        try:
            response = await self.anthropic_client.messages.create(
                model="claude-sonnet-4-20250514",
                max_tokens=512,
                messages=[{"role": "user", "content": prompt}],
            )
            text = response.content[0].text.strip()
            result = self._parse_json_safe(text, {})
            if "web_queries" in result and "github_query" in result:
                if "required_apis" not in result:
                    result["required_apis"] = []
                return result
        except Exception:
            pass

        return {
            "web_queries": [f"{idea} tool service app", f"{idea} alternative competitor"],
            "github_query": idea,
            "required_apis": [],
        }

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 1 & 2: Search (parallel)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def _search_web(self, idea: str, ai_queries: list[str] | None = None) -> dict:
        """Search web for competitors using Tavily API with AI-optimized queries."""
        if not self.tavily_api_key:
            return {"competitors": [], "summary": "ê²€ìƒ‰ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", "raw_count": 0}

        query1 = ai_queries[0] if ai_queries and len(ai_queries) > 0 else f"{idea} tool service app"
        query2 = ai_queries[1] if ai_queries and len(ai_queries) > 1 else f"{idea} alternative competitor similar"

        try:
            async with httpx.AsyncClient(timeout=15.0) as client:
                resp1, resp2 = await asyncio.gather(
                    client.post("https://api.tavily.com/search", json={
                        "api_key": self.tavily_api_key, "query": query1,
                        "max_results": 8, "search_depth": "basic",
                    }),
                    client.post("https://api.tavily.com/search", json={
                        "api_key": self.tavily_api_key, "query": query2,
                        "max_results": 5, "search_depth": "basic",
                    }),
                )

                competitors = []
                seen_urls = set()
                for resp in [resp1, resp2]:
                    for r in resp.json().get("results", []):
                        url = r.get("url", "")
                        if url not in seen_urls:
                            seen_urls.add(url)
                            competitors.append({
                                "title": r.get("title", ""),
                                "url": url,
                                "snippet": r.get("content", "")[:200],
                            })

                return {
                    "competitors": competitors[:10],
                    "raw_count": len(competitors),
                    "summary": f"ì›¹ì—ì„œ {len(competitors)}ê°œì˜ ê´€ë ¨ ê²°ê³¼ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.",
                }
        except Exception as e:
            return {"competitors": [], "summary": f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}", "raw_count": 0}

    async def _search_github(self, idea: str, ai_query: str = "") -> dict:
        """Search GitHub for similar projects with AI-optimized query."""
        try:
            headers = {"Accept": "application/vnd.github.v3+json"}
            if self.github_token:
                headers["Authorization"] = f"token {self.github_token}"

            query = (ai_query or idea).replace(" ", "+")

            async with httpx.AsyncClient(timeout=15.0) as client:
                resp = await client.get(
                    f"https://api.github.com/search/repositories?q={query}&sort=stars&order=desc&per_page=10",
                    headers=headers,
                )
                data = resp.json()

                repos = []
                for item in data.get("items", []):
                    repos.append({
                        "name": item.get("full_name", ""),
                        "description": (item.get("description") or "")[:200],
                        "stars": item.get("stargazers_count", 0),
                        "url": item.get("html_url", ""),
                        "language": item.get("language", ""),
                        "updated": item.get("updated_at", "")[:10],
                    })

                return {
                    "repos": repos,
                    "total_count": data.get("total_count", 0),
                    "summary": f"GitHubì—ì„œ {data.get('total_count', 0)}ê°œì˜ ê´€ë ¨ ì €ì¥ì†Œë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.",
                }
        except Exception as e:
            return {"repos": [], "total_count": 0, "summary": f"GitHub ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}"}

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Relevance filtering: AI removes irrelevant search results
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def _filter_relevance(self, idea: str, competitors: dict, github_results: dict) -> dict:
        """Use Claude to filter out irrelevant search results."""
        if not self.anthropic_client:
            return {"competitors": competitors, "github": github_results}

        comp_list = competitors.get("competitors", [])[:10]
        repo_list = github_results.get("repos", [])[:10]

        if not comp_list and not repo_list:
            return {"competitors": competitors, "github": github_results}

        items_text = ""
        for i, c in enumerate(comp_list):
            items_text += f"WEB_{i}: {c['title']} â€” {c['snippet'][:100]}\n"
        for i, r in enumerate(repo_list):
            items_text += f"GH_{i}: {r['name']} â€” {r['description'][:100]}\n"

        prompt = f"""ì•„ì´ë””ì–´: {idea}

ì•„ë˜ ê²€ìƒ‰ ê²°ê³¼ ì¤‘ ì´ ì•„ì´ë””ì–´ì™€ ì‹¤ì œë¡œ ê´€ë ¨ëœ ê²½ìŸ ì œí’ˆ/ìœ ì‚¬ í”„ë¡œì íŠ¸ë§Œ ì„ ë³„í•˜ì„¸ìš”.
ë‰´ìŠ¤ ê¸°ì‚¬, íŠœí† ë¦¬ì–¼, ê´€ë ¨ ì—†ëŠ” ë„êµ¬ëŠ” ì œì™¸í•˜ì„¸ìš”.

{items_text}

ë°˜ë“œì‹œ ìˆœìˆ˜ JSONìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{{
  "relevant_web": [0, 2, 5],
  "relevant_gh": [0, 1, 3]
}}

ìˆ«ìëŠ” ìœ„ ëª©ë¡ì˜ ì¸ë±ìŠ¤ì…ë‹ˆë‹¤. ê´€ë ¨ ìˆëŠ” ê²ƒë§Œ í¬í•¨í•˜ì„¸ìš”."""

        try:
            response = await self.anthropic_client.messages.create(
                model="claude-sonnet-4-20250514",
                max_tokens=256,
                messages=[{"role": "user", "content": prompt}],
            )
            text = response.content[0].text.strip()
            result = self._parse_json_safe(text, {})

            relevant_web = result.get("relevant_web", list(range(len(comp_list))))
            relevant_gh = result.get("relevant_gh", list(range(len(repo_list))))

            filtered_comps = [comp_list[i] for i in relevant_web if i < len(comp_list)]
            filtered_repos = [repo_list[i] for i in relevant_gh if i < len(repo_list)]

            filtered_competitors = {
                "competitors": filtered_comps,
                "raw_count": competitors.get("raw_count", 0),
                "filtered_count": len(filtered_comps),
                "summary": f"{competitors.get('raw_count', 0)}ê°œ ì¤‘ {len(filtered_comps)}ê°œê°€ ì‹¤ì œ ê²½ìŸ ì œí’ˆìœ¼ë¡œ í™•ì¸ë¨",
            }
            filtered_github = {
                "repos": filtered_repos,
                "total_count": github_results.get("total_count", 0),
                "filtered_count": len(filtered_repos),
                "summary": f"{github_results.get('total_count', 0)}ê°œ ì¤‘ {len(filtered_repos)}ê°œê°€ ì‹¤ì œ ìœ ì‚¬ í”„ë¡œì íŠ¸ë¡œ í™•ì¸ë¨",
            }

            return {"competitors": filtered_competitors, "github": filtered_github}
        except Exception:
            return {"competitors": competitors, "github": github_results}

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # API / Data source verification
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def _check_data_sources(self, idea: str, required_apis: list[dict]) -> dict:
        """Verify API/data source availability by actually checking URLs."""
        results = []

        async with httpx.AsyncClient(timeout=10.0, follow_redirects=True) as client:
            for api in required_apis:
                check = {
                    "name": api.get("name", ""),
                    "purpose": api.get("purpose", ""),
                    "known_blocked": api.get("known_blocked", False),
                    "alternatives": api.get("alternatives", []),
                    "status": "unknown",
                    "detail": "",
                }

                if api.get("known_blocked"):
                    check["status"] = "blocked"
                    check["detail"] = "í¬ë¡¤ë§/API ì ‘ê·¼ì´ ì°¨ë‹¨ëœ ê²ƒìœ¼ë¡œ ì•Œë ¤ì§„ ì„œë¹„ìŠ¤"
                    results.append(check)
                    continue

                check_url = api.get("check_url", "")
                if check_url:
                    try:
                        resp = await client.head(check_url)
                        if resp.status_code < 400:
                            check["status"] = "available"
                            check["detail"] = f"API ë¬¸ì„œ í™•ì¸ë¨ (HTTP {resp.status_code})"
                        else:
                            check["status"] = "uncertain"
                            check["detail"] = f"API ë¬¸ì„œ ì ‘ê·¼ ë¶ˆê°€ (HTTP {resp.status_code})"
                    except Exception:
                        check["status"] = "uncertain"
                        check["detail"] = "API ë¬¸ì„œ URLì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŒ"
                else:
                    check["status"] = "no_docs"
                    check["detail"] = "ê³µì‹ API ë¬¸ì„œ URLì„ ì°¾ì„ ìˆ˜ ì—†ìŒ"

                results.append(check)

        blocked_count = sum(1 for r in results if r["status"] == "blocked")
        uncertain_count = sum(1 for r in results if r["status"] in ("uncertain", "no_docs"))
        total = len(results)

        if total == 0:
            risk_level = "low"
            risk_score = 0
        elif blocked_count > 0:
            risk_level = "critical"
            risk_score = min(100, blocked_count * 40 + uncertain_count * 15)
        elif uncertain_count > 0:
            risk_level = "moderate"
            risk_score = min(80, uncertain_count * 20)
        else:
            risk_level = "low"
            risk_score = 0

        return {
            "checks": results,
            "risk_level": risk_level,
            "risk_score": risk_score,
            "summary": self._build_api_check_summary(results),
        }

    def _build_api_check_summary(self, results: list[dict]) -> str:
        if not results:
            return "íŠ¹ë³„í•œ ì™¸ë¶€ ë°ì´í„° ì†ŒìŠ¤ê°€ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
        blocked = [r["name"] for r in results if r["status"] == "blocked"]
        available = [r["name"] for r in results if r["status"] == "available"]
        parts = []
        if blocked:
            parts.append(f"ì ‘ê·¼ ì°¨ë‹¨: {', '.join(blocked)}")
        if available:
            parts.append(f"ì‚¬ìš© ê°€ëŠ¥: {', '.join(available)}")
        return " | ".join(parts) if parts else "ë°ì´í„° ì†ŒìŠ¤ í™•ì¸ ì™„ë£Œ"

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Claude streaming wrapper
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def _call_claude_stream(self, prompt: str, fallback: dict, max_tokens: int = 1024) -> AsyncGenerator[dict, None]:
        if not self.anthropic_client:
            yield {"type": "result", "result": fallback}
            return
        try:
            collected_text = ""
            char_count = 0
            async with self.anthropic_client.messages.stream(
                model="claude-sonnet-4-20250514",
                max_tokens=max_tokens,
                messages=[{"role": "user", "content": prompt}],
            ) as stream:
                async for text in stream.text_stream:
                    collected_text += text
                    char_count += len(text)
                    if char_count >= 80:
                        char_count = 0
                        yield {"type": "progress", "text": f"AI ì‘ë‹µ ìƒì„± ì¤‘... ({len(collected_text)}ì)"}
            result = self._parse_json_safe(collected_text.strip(), fallback)
            yield {"type": "result", "result": result}
        except Exception:
            yield {"type": "result", "result": fallback}

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 3: Feasibility (with real competitor data + API checks)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def _stream_feasibility(self, idea: str, mode: str, filtered: dict, api_check: dict) -> AsyncGenerator[dict, None]:
        fallback = self._fallback_feasibility(idea)
        prompt = self._build_feasibility_prompt(idea, mode, filtered, api_check)
        async for event in self._call_claude_stream(prompt, fallback, max_tokens=1500):
            yield event

    def _build_feasibility_prompt(self, idea: str, mode: str, filtered: dict, api_check: dict) -> str:
        mode_context = {
            "hackathon": "4ì‹œê°„ í•´ì»¤í†¤ (1ì¸ ê°œë°œì)",
            "startup": "ì´ˆê¸° ìŠ¤íƒ€íŠ¸ì—… (3-5ëª… íŒ€, 3ê°œì›”)",
            "sideproject": "ì‚¬ì´ë“œ í”„ë¡œì íŠ¸ (1-2ëª…, ì£¼ë§ ê°œë°œ)",
        }
        competitors = filtered.get("competitors", {})
        github = filtered.get("github", {})

        comp_detail = "\n".join(
            [f"- {c['title']}: {c['snippet']}" for c in competitors.get("competitors", [])[:5]]
        ) or "ê´€ë ¨ ê²½ìŸ ì œí’ˆ ì—†ìŒ"

        gh_detail = "\n".join(
            [f"- {r['name']} ({r.get('language', '?')}, â­{r['stars']}): {r['description']}"
             for r in github.get("repos", [])[:5]]
        ) or "ê´€ë ¨ ì˜¤í”ˆì†ŒìŠ¤ ì—†ìŒ"

        api_detail = ""
        if api_check.get("checks"):
            api_lines = []
            for check in api_check["checks"]:
                status_emoji = {"available": "âœ…", "blocked": "ğŸš«", "uncertain": "âš ï¸", "no_docs": "â“"}.get(check["status"], "â“")
                alt_text = f" (ëŒ€ì•ˆ: {', '.join(check['alternatives'])})" if check["alternatives"] else ""
                api_lines.append(f"  {status_emoji} {check['name']}: {check['detail']}{alt_text}")
            api_detail = "\n".join(api_lines)
        else:
            api_detail = "  íŠ¹ë³„í•œ ì™¸ë¶€ API ë¶ˆí•„ìš”"

        return f"""ë‹¹ì‹ ì€ ê¸°ìˆ  ì‹¤í˜„ì„±ì„ ëƒ‰ì •í•˜ê²Œ ë¶„ì„í•˜ëŠ” ì‹œë‹ˆì–´ ê°œë°œìì…ë‹ˆë‹¤.
íŠ¹íˆ ë°ì´í„° ì†ŒìŠ¤ ì ‘ê·¼ ê°€ëŠ¥ì„±ì„ ì‹¤ì œë¡œ ê²€ì¦í•œ ê²°ê³¼ê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë‹ˆ ë°˜ë“œì‹œ ë°˜ì˜í•˜ì„¸ìš”.

ì•„ì´ë””ì–´: {idea}
ê°œë°œ í™˜ê²½: {mode_context.get(mode, mode_context["hackathon"])}

â–  ì‹¤ì œ ê²€ìƒ‰ëœ ê²½ìŸ ì œí’ˆ ({competitors.get("filtered_count", competitors.get("raw_count", 0))}ê°œ í™•ì¸ë¨):
{comp_detail}

â–  ì‹¤ì œ ê²€ìƒ‰ëœ GitHub ìœ ì‚¬ í”„ë¡œì íŠ¸ ({github.get("filtered_count", github.get("total_count", 0))}ê°œ í™•ì¸ë¨):
{gh_detail}

â–  ë°ì´í„° ì†ŒìŠ¤/API ì ‘ê·¼ì„± ê²€ì¦ ê²°ê³¼ (ìœ„í—˜ë„: {api_check.get("risk_level", "unknown")}):
{api_detail}

ì¤‘ìš”: ğŸš«ë¡œ í‘œì‹œëœ APIëŠ” ì‹¤ì œë¡œ ì ‘ê·¼ì´ ì°¨ë‹¨ë˜ì—ˆìœ¼ë¯€ë¡œ, ì´ ì•„ì´ë””ì–´ì˜ í•µì‹¬ ê¸°ëŠ¥ì— ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤.
ëŒ€ì•ˆì´ ìˆë‹¤ë©´ ëŒ€ì•ˆ ê¸°ë°˜ì˜ êµ¬í˜„ ê°€ëŠ¥ì„±ë„ í‰ê°€í•˜ì„¸ìš”.

ë°˜ë“œì‹œ ìˆœìˆ˜ JSONìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:

{{
  "overall_feasibility": "possible" | "partial" | "difficult",
  "score": 0-100,
  "tech_requirements": [
    {{"name": "ê¸°ìˆ /APIëª…", "available": true/false, "difficulty": "easy|medium|hard", "note": "í•œì¤„ ì„¤ëª… (ì°¨ë‹¨ëœ ê²½ìš° ëŒ€ì•ˆ ëª…ì‹œ)"}}
  ],
  "key_risks": ["ë¦¬ìŠ¤í¬ 1 (êµ¬ì²´ì ìœ¼ë¡œ)", "ë¦¬ìŠ¤í¬ 2"],
  "data_source_risks": ["ë°ì´í„° ì ‘ê·¼ ê´€ë ¨ êµ¬ì²´ì  ë¦¬ìŠ¤í¬"],
  "time_estimate": "ì˜ˆìƒ ê°œë°œ ì‹œê°„",
  "summary": "í•œì¤„ ì¢…í•© íŒë‹¨"
}}"""

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 4: Differentiation (with full filtered data)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def _stream_differentiation(self, idea: str, filtered: dict) -> AsyncGenerator[dict, None]:
        competitors = filtered.get("competitors", {})
        github = filtered.get("github", {})
        fallback = self._fallback_differentiation(idea, competitors, github)
        prompt = self._build_differentiation_prompt(idea, filtered)
        async for event in self._call_claude_stream(prompt, fallback, max_tokens=1500):
            yield event

    def _build_differentiation_prompt(self, idea: str, filtered: dict) -> str:
        competitors = filtered.get("competitors", {})
        github = filtered.get("github", {})

        competitor_list = "\n".join(
            [f"- {c['title']}: {c['snippet']}" for c in competitors.get("competitors", [])[:7]]
        ) or "ê´€ë ¨ ê²½ìŸ ì œí’ˆ ì—†ìŒ"

        github_list = "\n".join(
            [f"- {r['name']} ({r.get('language', '?')}, â­{r['stars']}): {r['description']}"
             for r in github.get("repos", [])[:7]]
        ) or "ê´€ë ¨ ìœ ì‚¬ í”„ë¡œì íŠ¸ ì—†ìŒ"

        filter_note = ""
        raw_web = competitors.get("raw_count", 0)
        filtered_web = competitors.get("filtered_count", raw_web)
        if raw_web != filtered_web:
            filter_note = f"\nì°¸ê³ : ì›¹ ê²€ìƒ‰ {raw_web}ê±´ ì¤‘ {filtered_web}ê±´ë§Œ ì‹¤ì œ ê²½ìŸ ì œí’ˆìœ¼ë¡œ í™•ì¸ë¨ (ë‚˜ë¨¸ì§€ëŠ” ë‰´ìŠ¤/ê¸°ì‚¬ ë“±)"

        return f"""ë‹¹ì‹ ì€ Devil's Advocateì…ë‹ˆë‹¤. ì•„ì´ë””ì–´ì˜ ì°¨ë³„í™” ê°€ëŠ¥ì„±ì„ ëƒ‰ì •í•˜ê²Œ ë¶„ì„í•˜ì„¸ìš”.

ì•„ì´ë””ì–´: {idea}
{filter_note}

â–  ì‹¤ì œ ê²½ìŸ ì œí’ˆ (ê´€ë ¨ì„± ê²€ì¦ ì™„ë£Œ):
{competitor_list}

â–  GitHub ìœ ì‚¬ í”„ë¡œì íŠ¸ (ê´€ë ¨ì„± ê²€ì¦ ì™„ë£Œ):
{github_list}

ë°˜ë“œì‹œ ìˆœìˆ˜ JSONìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:

{{
  "competition_level": "blue_ocean" | "moderate" | "red_ocean",
  "competition_score": 0-100,
  "existing_solutions": [
    {{"name": "ì œí’ˆ/í”„ë¡œì íŠ¸ëª…", "similarity": 0-100, "weakness": "ì•½ì "}}
  ],
  "unique_angles": ["ì°¨ë³„í™” í¬ì¸íŠ¸ 1", "ì°¨ë³„í™” í¬ì¸íŠ¸ 2"],
  "devil_arguments": ["ì´ ì•„ì´ë””ì–´ê°€ ì‹¤íŒ¨í•˜ëŠ” ì´ìœ  1", "ì´ìœ  2", "ì´ìœ  3"],
  "pivot_suggestions": ["ëŒ€ì•ˆ ì•„ì´ë””ì–´ 1", "ëŒ€ì•ˆ ì•„ì´ë””ì–´ 2"],
  "summary": "í•œì¤„ ì¢…í•©"
}}"""

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 5: Verdict (with ALL analysis data â€” full context)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def _stream_verdict(self, idea: str, mode: str, filtered: dict, feasibility: dict, differentiation: dict, api_check: dict) -> AsyncGenerator[dict, None]:
        fallback = self._fallback_verdict(feasibility, differentiation)
        prompt = self._build_verdict_prompt(idea, mode, filtered, feasibility, differentiation, api_check)
        async for event in self._call_claude_stream(prompt, fallback, max_tokens=1500):
            yield event

    def _build_verdict_prompt(self, idea: str, mode: str, filtered: dict, feasibility: dict, differentiation: dict, api_check: dict) -> str:
        competitors = filtered.get("competitors", {})
        github = filtered.get("github", {})

        tech_reqs = "\n".join(
            [f"  - {t['name']}: {'âœ…' if t.get('available') else 'âŒ'} ({t.get('difficulty', '?')}) {t.get('note', '')}"
             for t in feasibility.get("tech_requirements", [])]
        ) or "  ì •ë³´ ì—†ìŒ"

        existing = "\n".join(
            [f"  - {s['name']}: ìœ ì‚¬ë„ {s.get('similarity', '?')}%, ì•½ì : {s.get('weakness', '?')}"
             for s in differentiation.get("existing_solutions", [])]
        ) or "  ì •ë³´ ì—†ìŒ"

        api_summary = ""
        blocked_apis = [c for c in api_check.get("checks", []) if c["status"] == "blocked"]
        if blocked_apis:
            api_summary = "\nâ–  ë°ì´í„° ì ‘ê·¼ ì°¨ë‹¨:\n" + "\n".join(
                [f"  - {a['name']}: {a['detail']} (ëŒ€ì•ˆ: {', '.join(a.get('alternatives', ['ì—†ìŒ']))})"
                 for a in blocked_apis]
            )
            api_summary += f"\n  â†’ ë°ì´í„° ì†ŒìŠ¤ ìœ„í—˜ë„: {api_check.get('risk_level', '?')} (ì ìˆ˜: {api_check.get('risk_score', 0)})"

        return f"""ë‹¹ì‹ ì€ í•´ì»¤í†¤ ì•„ì´ë””ì–´ ì‹¬íŒê´€ì…ë‹ˆë‹¤. ì•„ë˜ì˜ ëª¨ë“  ë¶„ì„ ë°ì´í„°ë¥¼ êµì°¨ ê²€ì¦í•˜ì—¬ ìµœì¢… íŒì •ì„ ë‚´ë¦¬ì„¸ìš”.

ì•„ì´ë””ì–´: {idea}
ëª¨ë“œ: {mode}

â–  ê²½ìŸ í˜„í™©:
- ì‹¤ì œ ê²½ìŸ ì œí’ˆ: {competitors.get("filtered_count", competitors.get("raw_count", 0))}ê°œ
- GitHub ìœ ì‚¬ í”„ë¡œì íŠ¸: {github.get("filtered_count", github.get("total_count", 0))}ê°œ
- ê²½ìŸ ìˆ˜ì¤€: {differentiation.get("competition_level", "unknown")}
- ê²½ìŸ ì ìˆ˜: {differentiation.get("competition_score", "?")}/100

â–  ê¸°ì¡´ ì†”ë£¨ì…˜ ìƒì„¸:
{existing}

â–  ê¸°ìˆ  ì‹¤í˜„ì„±:
- ì ìˆ˜: {feasibility.get("score", 50)}/100
- íŒì •: {feasibility.get("overall_feasibility", "unknown")}
- í•„ìš” ê¸°ìˆ :
{tech_reqs}
- í•µì‹¬ ë¦¬ìŠ¤í¬: {json.dumps(feasibility.get("key_risks", []), ensure_ascii=False)}
- ë°ì´í„° ì†ŒìŠ¤ ë¦¬ìŠ¤í¬: {json.dumps(feasibility.get("data_source_risks", []), ensure_ascii=False)}
{api_summary}

â–  ì°¨ë³„í™”:
- ì°¨ë³„í™” í¬ì¸íŠ¸: {json.dumps(differentiation.get("unique_angles", []), ensure_ascii=False)}
- Devil's Arguments: {json.dumps(differentiation.get("devil_arguments", []), ensure_ascii=False)}
- í”¼ë²— ì œì•ˆ: {json.dumps(differentiation.get("pivot_suggestions", []), ensure_ascii=False)}

êµì°¨ ê²€ì¦ ì§€ì¹¨:
1. feasibility scoreì™€ competition_scoreê°€ ëª¨ìˆœë˜ì§€ ì•ŠëŠ”ì§€ í™•ì¸
2. ë°ì´í„° ì†ŒìŠ¤ê°€ ì°¨ë‹¨ëœ ê²½ìš° feasibility ì ìˆ˜ë¥¼ ëŒ€í­ í•˜í–¥ ì¡°ì •
3. timing ì ìˆ˜ëŠ” ê²½ìŸ ì œí’ˆì˜ ìµœì‹ ì„±ê³¼ GitHub í”„ë¡œì íŠ¸ í™œë™ìœ¼ë¡œ íŒë‹¨
4. overall_scoreëŠ” ê°œë³„ ì ìˆ˜ì˜ ë‹¨ìˆœ í‰ê· ì´ ì•„ë‹Œ, ê°€ì¤‘ í‰ê°€

ë°˜ë“œì‹œ ìˆœìˆ˜ JSONìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:

{{
  "verdict": "GO" | "PIVOT" | "KILL",
  "confidence": 0-100,
  "overall_score": 0-100,
  "scores": {{
    "competition": 0-100,
    "feasibility": 0-100,
    "differentiation": 0-100,
    "timing": 0-100
  }},
  "one_liner": "í•œ ì¤„ íŒì • ì´ìœ ",
  "recommendation": "êµ¬ì²´ì  ì¶”ì²œ í–‰ë™",
  "alternative_ideas": ["ëŒ€ì•ˆ 1", "ëŒ€ì•ˆ 2", "ëŒ€ì•ˆ 3"]
}}"""

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Utilities
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _parse_json_safe(self, text: str, fallback: dict) -> dict:
        try:
            return json.loads(text)
        except json.JSONDecodeError:
            pass
        if "```" in text:
            try:
                json_str = text.split("```")[1]
                if json_str.startswith("json"):
                    json_str = json_str[4:]
                return json.loads(json_str.strip())
            except (json.JSONDecodeError, IndexError):
                pass
        try:
            start = text.index("{")
            end = text.rindex("}") + 1
            return json.loads(text[start:end])
        except (ValueError, json.JSONDecodeError):
            pass
        return fallback

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Fallbacks
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _fallback_feasibility(self, idea: str) -> dict:
        return {
            "overall_feasibility": "partial",
            "score": 50,
            "tech_requirements": [],
            "key_risks": ["LLM ë¶„ì„ ì‹¤íŒ¨ â€” fallback ë°ì´í„°ì…ë‹ˆë‹¤"],
            "data_source_risks": [],
            "time_estimate": "ì•Œ ìˆ˜ ì—†ìŒ",
            "summary": "AI ë¶„ì„ì„ ìˆ˜í–‰í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.",
        }

    def _fallback_differentiation(self, idea: str, competitors: dict, github_results: dict) -> dict:
        comp_count = competitors.get("raw_count", 0) + github_results.get("total_count", 0)
        level = "red_ocean" if comp_count > 20 else "moderate" if comp_count > 5 else "blue_ocean"
        return {
            "competition_level": level,
            "competition_score": max(0, 100 - comp_count * 5),
            "existing_solutions": [],
            "unique_angles": [],
            "devil_arguments": ["AI ë¶„ì„ ì—†ì´ëŠ” êµ¬ì²´ì  ì•½ì ì„ íŒŒì•…í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"],
            "pivot_suggestions": [],
            "summary": f"ê²½ìŸ ì œí’ˆ {comp_count}ê°œ ê¸°ë°˜ ìë™ íŒì •",
        }

    def _fallback_verdict(self, feasibility: dict, differentiation: dict) -> dict:
        f_score = feasibility.get("score", 50)
        d_score = differentiation.get("competition_score", 50)
        avg = (f_score + d_score) // 2
        verdict = "GO" if avg >= 70 else "PIVOT" if avg >= 40 else "KILL"
        return {
            "verdict": verdict,
            "confidence": 40,
            "overall_score": avg,
            "scores": {
                "competition": d_score,
                "feasibility": f_score,
                "differentiation": d_score,
                "timing": 50,
            },
            "one_liner": "AI ë¶„ì„ ì—†ì´ ì ìˆ˜ ê¸°ë°˜ ìë™ íŒì •ì…ë‹ˆë‹¤.",
            "recommendation": "API í‚¤ë¥¼ ì„¤ì •í•˜ë©´ ë” ì •í™•í•œ ë¶„ì„ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            "alternative_ideas": [],
        }
